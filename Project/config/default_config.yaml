# Name of your wandb run
name: Default

# Description of your wandb run
notes: Default

# Hyperparameters
config: 
  epochs: 100
  learning_rate: 0.001
  optimizer:
    optimizer_type: Adam
    lr_scheduler: CosineAnnealingLR
    lr: 1e-3
  data:
    dataset: CIFAR10
    args:
      root: data
      batch_size: 64
  model:
    model_class: LeNet
    criterion: CrossEntropyLoss
    LeNet:
      conf_name: LeNet5-BN
      input_shape: [1, 28, 28]
      num_classes: 10
  num_workers: 4
  seed: 42
  log_interval: 10
  save_model: True
  noise_settings.default.noise_type: NoNoise
  noise_settings.layer_wise:
    layer_index: 5
    enable_in_training: 1


