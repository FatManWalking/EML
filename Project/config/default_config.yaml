# Name of your wandb run
name: Default

# Description of your wandb run
notes: Default

# Hyperparameters
config: 
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  optimizer:
    optimizer_type: Adam
    lr_scheduler: CosineAnnealingLR
    lr: 1e-3
  data:
    dataset: CIFAR10
  model:
    model_class: LeNet
    criterion: CrossEntropyLoss
    LeNet:
      conf_name: LeNet5-BN
  num_workers: 4
  seed: 42
  log_interval: 10
  save_model: True



